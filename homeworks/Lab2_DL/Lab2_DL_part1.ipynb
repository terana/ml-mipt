{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Overfit it (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с датасетом [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) (*hint: он доступен в torchvision*).\n",
    "\n",
    "Ваша задача состоит в следующем:\n",
    "1. Обучить сеть, которая покажет >= 0.92 test accuracy.\n",
    "2. Пронаблюдать и продемонстрировать процесс переобучения сети с увеличением числа параметров (==нейронов) и/или числа слоев и продемонстрировать это наглядно (например, на графиках).\n",
    "3. Попробовать частично справиться с переобучением с помощью подходящих приемов (Dropout/batchnorm/augmentation etc.)\n",
    "\n",
    "*Примечание*: Пункты 2 и 3 взаимосвязаны, в п.3 Вам прелагается сделать полученную в п.2 сеть менее склонной к переобучению. Пункт 1 является независимым от пунктов 2 и 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomAffine(30, [0.2, 0.2], (0.7, 1.3)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "fashion_mnist_train = FashionMNIST('data', download=True, train=True, transform=augment)\n",
    "fashion_mnist_test = FashionMNIST('data', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneDim(nn.Module):\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(what, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "today = dt.now().strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_batch_gen, test_batch_gen, lr, label=\"\"):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train(True)\n",
    "        for (X_batch, y_batch) in train_batch_gen:\n",
    "            X_batch, y_batch = Variable(torch.FloatTensor(X_batch)).cpu(), Variable(torch.LongTensor(y_batch)).cpu()\n",
    "            loss = F.cross_entropy(model.cpu()(X_batch), y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            train_loss.append(loss.cpu().data.numpy())\n",
    "\n",
    "        model.train(False)\n",
    "        for X_batch, y_batch in test_batch_gen:\n",
    "            logits = model(Variable(torch.FloatTensor(X_batch).cpu()))\n",
    "            test_acc.append(np.mean((y_batch.cpu() == logits.max(1)[1].data.cpu()).numpy()))\n",
    "\n",
    "        av_test_acc = np.mean(test_acc[-len(test_batch_gen)::])\n",
    "        av_train_loss = np.mean(train_loss[-len(train_batch_gen):])\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - {time.time() - start_time:.1f}s  training loss: {av_train_loss} test accuracy: {av_test_acc:.3f}\")\n",
    "        \n",
    "        torch.save(model.state_dict(), f\"{today}_model_{label}_epoch_{epoch + 1}_test_acc_{av_test_acc}_loss_{av_train_loss:.6f}\")\n",
    "        save(train_loss, f\"{today}_training_loss_epoch_{epoch}\")\n",
    "        save(test_acc, f\"{today}_test_acc_epoch_{epoch}\")\n",
    "        \n",
    "        return train_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_conv = 64\n",
    "init_dense = 512\n",
    "\n",
    "model = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, init_conv, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv),\n",
    "    \n",
    "    nn.Conv2d(init_conv, init_conv, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv),\n",
    "    nn.MaxPool2d(2),\n",
    "    \n",
    "    nn.Conv2d(init_conv, init_conv * 2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv * 2),\n",
    "    \n",
    "    nn.Conv2d(init_conv * 2, init_conv * 2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv * 2),\n",
    "    nn.MaxPool2d(2),\n",
    "    \n",
    "    nn.Conv2d(init_conv * 2, init_conv * 4, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv * 4),\n",
    "    \n",
    "    nn.Conv2d(init_conv * 4, init_conv * 4, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv * 4),\n",
    "    \n",
    "    OneDim(),\n",
    "    nn.Linear(7 * 7 * init_conv * 4, init_dense),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense, init_dense),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense, init_dense),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_batch_gen = torch.utils.data.DataLoader(fashion_mnist_train, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)\n",
    "test_batch_gen = torch.utils.data.DataLoader(fashion_mnist_test, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_acc = train(model=model, \n",
    "                             num_epochs=15, \n",
    "                             train_batch_gen=train_batch_gen, \n",
    "                             test_batch_gen=test_batch_gen,\n",
    "                             lr=0.001, \n",
    "                             label=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train = FashionMNIST('data', download=True, train=True, transform=test)\n",
    "fashion_mnist_test = FashionMNIST('data', download=True, train=False, transform=test)\n",
    "\n",
    "batch_size = 128\n",
    "train_batch_gen = torch.utils.data.DataLoader(fashion_mnist_train, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)\n",
    "test_batch_gen = torch.utils.data.DataLoader(fashion_mnist_test, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_conv = 256\n",
    "init_dense = 4096 * 2\n",
    "\n",
    "over_model = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, init_conv, 7, padding=2),\n",
    "    \n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm2d(init_conv),\n",
    "    nn.MaxPool2d(4),\n",
    "    \n",
    "    to_1d(),\n",
    "    nn.Linear(6 * 6 * init_conv, init_dense),\n",
    "#     nn.Dropout(p=0.1),\n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense, init_dense // 2),\n",
    "#     nn.Dropout(p=0.1),\n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense // 2, init_dense // 4),\n",
    "    nn.ReLU(),\n",
    "#     nn.Dropout(p=0.2),\n",
    "#     nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense // 4, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_train_loss, over_test_acc = train(model=over_model, \n",
    "                                       num_epochs=30, \n",
    "                                       train_batch_gen=train_batch_gen, \n",
    "                                       test_batch_gen=test_batch_gen,\n",
    "                                       lr=0.003, \n",
    "                                       label=\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(over_train_loss[3:], c='r')\n",
    "plt.plot(1-np.array(over_test_acc[3:]))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_conv = 256\n",
    "init_dense = 4096 * 2\n",
    "\n",
    "fixed_model = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, init_conv, 7, padding=2),\n",
    "    \n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(init_conv),\n",
    "    nn.MaxPool2d(4),\n",
    "    \n",
    "    to_1d(),\n",
    "    nn.Linear(6 * 6 * init_conv, init_dense),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(init_dense),\n",
    "    \n",
    "    nn.Linear(init_dense, init_dense // 2),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(init_dense // 2),\n",
    "    \n",
    "    nn.Linear(init_dense // 2, init_dense // 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.BatchNorm1d(init_dense // 4),\n",
    "    \n",
    "    nn.Linear(init_dense // 4, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_train_loss, fixed_test_acc = train(model=fixed_model, \n",
    "                                         num_epochs=30,\n",
    "                                         train_batch_gen=train_batch_gen,\n",
    "                                         test_batch_gen=test_batch_gen,\n",
    "                                         lr=0.003,\n",
    "                                         label=\"fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94d6dde7d125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Overfitted train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_over\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m222\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8 * 2, 4 * 3))\n",
    "plt.subplot(221)\n",
    "plt.title('Overfitted train loss')\n",
    "plt.plot(over_train_loss[50:])\n",
    "plt.subplot(222)\n",
    "plt.title('Fixed train loss')\n",
    "plt.plot(fixed_train_loss[50:])\n",
    "plt.subplot(223)\n",
    "plt.title('Overfitted test accuracy')\n",
    "plt.plot(over_test_acc[50:])\n",
    "plt.subplot(224)\n",
    "plt.title('Fixed test accuracy')\n",
    "plt.plot(fixed_test_acc[50:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эффект переобучения заметен не очень сильно. Добавление dropout и batchnorm слоёв позволило получить более стабильную картину обучения и более стабильные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
