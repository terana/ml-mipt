{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework01: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02 seminar](https://github.com/ml-mipt/ml-mipt/blob/advanced/week02_CNN_n_Vanishing_gradient/week02_CNN_for_texts.ipynb). Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./Train_rev1.csv' does not exist: b'./Train_rev1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cb6f75350bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# !tar -xvzf ./Train_rev1.csv.tar.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Train_rev1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./Train_rev1.csv' does not exist: b'./Train_rev1.csv'"
     ]
    }
   ],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "# !curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/ml-mipt/ml-mipt/advanced/homeworks/homework1_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "# data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d634c2295714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[27162,     1,     1,     1,     1,     1],\n",
       "        [14188, 21405,  8341,   195,  8341, 18670],\n",
       "        [ 6296, 21691,     1,     1,     1,     1]], dtype=int32),\n",
       " 'FullDescription': array([[18132,   891,  5941,   156,  6006, 26682,   891,    80, 23248,\n",
       "          8814, 21556, 11453,  6835,   891,     0, 27181, 13699, 16658,\n",
       "         31456,   891, 12850, 30654, 22347, 30654, 16658,  8879,   891,\n",
       "         11458, 27162, 33479, 31438, 23421,     0, 27181,  2545,   965,\n",
       "         18602, 23921, 22124, 24167, 16156,  9000,  6835,  3512, 15402,\n",
       "         28444, 18704, 33198,   556, 33591, 11082, 30985, 25078,   167,\n",
       "         32718,  2545, 27195,  2120, 11458, 27162, 30762, 24244, 27159,\n",
       "          2166,  1465, 29566,  9238, 30762, 30411,  9239,   167,  9951,\n",
       "         15444, 32072,  2166, 33043, 24786, 21405, 21425, 29996, 32718,\n",
       "         14109,   965, 12850, 30654,  2166, 22347, 30654, 23415,  3137,\n",
       "           167, 23212, 28899,  6314,   891,   965,   167, 32969, 33635,\n",
       "          2545,  3137, 12466, 22347, 30654, 21784, 12850, 30654, 21784,\n",
       "          4353,  3235,   167, 12769, 32945,  8381,  2545, 33635,  3137,\n",
       "         23212,  2395,  5016,  6344,  3742, 30512, 16658, 32637, 21870,\n",
       "         23459,  2662, 33468,   167, 30895,   167,  6681,   195, 16679,\n",
       "           195, 27163,    80,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
       "        [14188, 21405,  8341,   195,  8341, 18670,   195,  4886, 18670,\n",
       "         20386,  6347, 16289,   965, 29048, 18842, 18004, 29558, 21405,\n",
       "          7865, 27463,   156, 18850,  8341,   156, 15800,  2166,  2142,\n",
       "         27463,  2166, 14109, 21433,  1297, 30411, 13366,   167,  9888,\n",
       "         30762, 15999, 24144, 30487,  2545,  1321, 27195,   965, 20697,\n",
       "         14188, 21405,  8341, 30762, 18659, 30411,  8341, 27463, 30080,\n",
       "          2166, 30411, 30103,  8422, 30762,  8422,  4938, 15922,   156,\n",
       "         15800,  2166,  2149, 25729,   167, 30411, 14188, 21405,  8341,\n",
       "         33079,  3607, 25722, 30762, 18581,   156, 18659,  2166, 29566,\n",
       "         30411,  8341, 23177,  2166, 27463, 30407,  8704, 15652, 16079,\n",
       "         30411,  4938, 12769,   965, 32075, 21405,  6361,    32, 12105,\n",
       "           156, 18850,   156,  7865,  3512, 10866,    63, 10781,  8341,\n",
       "         11922,  1219,   156, 24569,   156, 15916,  2166, 23976,  2662,\n",
       "         25722,   167, 30411, 29406, 14188, 21405,  8341, 33079, 14109,\n",
       "         22414, 11453, 15402,   965,  8341,  5726, 10866,  2166, 33079,\n",
       "          3607, 30135,  3189, 21405,    32,  4978, 21084, 20566, 12351,\n",
       "         15402,    63, 30411, 12426,   891, 26827, 32097, 18509, 20145,\n",
       "         11288,  4938, 15922, 30842,    32,  6575, 33403,  3607, 23686,\n",
       "            63,  8341, 24218, 17683,  2395, 21133, 12466,   965, 12518,\n",
       "          9328,  2166, 15293,  7195, 12466, 30512, 11759, 21721, 33209,\n",
       "           965, 13360, 17569, 15402,  7865, 27463,   167,  3771, 15444,\n",
       "          6886, 26682,   156,  4266,   156, 22667,   156, 14232,   156,\n",
       "         13831, 19294,   156,  8785, 11116,  2166,   965,  6835,  5303,\n",
       "         21784,  5303,  1937, 16038, 13699, 23204, 16289,  1307,  2662,\n",
       "          2120, 10572,  1675, 15402, 25443, 30762, 30512, 31993,   167],\n",
       "        [    0, 22697, 32796, 33738, 19891, 33738, 12742, 33738,  7677,\n",
       "         21595,  2662,  2166, 32960, 25722, 13153, 21425,  6296, 30762,\n",
       "         14446, 28850, 15447,  6296,     0,   156, 21433,   156,     0,\n",
       "         11116,  9951, 15444, 32005,   156,  9947,   156, 19971,   156,\n",
       "          4749,   156, 10583, 32650,  3965, 11116,   167, 20357,  3607,\n",
       "         12291,  2166, 33092, 30762,  9526, 22102,  8915, 30762, 14109,\n",
       "         11453, 15402, 30512, 17932, 21405, 33306, 23212,  5124,  8062,\n",
       "         25112, 17932,    80,    80,  2166, 17627, 33642, 20418,   156,\n",
       "         30226, 21196,  2166, 16658, 15137, 21196,   891,  7841,   195,\n",
       "             0,    80,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
       "       dtype=int32),\n",
       " 'Categorical': array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0733],\n",
       "        [0.0801],\n",
       "        [0.0592]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 225)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbb40c40131c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Categorical'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch['Categorical'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/Users/macder/ml_advanced/ml-mipt/homeworks/homework1_three_headed_network/network.py'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. It should be found out by you.\n",
    "    \n",
    "    # categorical: 3756 -> 64\n",
    "    # title: max_len*hid_size/2 = 5*64\n",
    "    # description: 64 * 64\n",
    "    # in sum it is 5964\n",
    "    \n",
    "    concat_number_of_features=4480\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-26f99ccd69a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_advanced/ml-mipt/homeworks/homework1_three_headed_network/network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, whole_input)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfull_beg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mfull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_beg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_max_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_adaptive_max_pool1d\u001b[0;34m(input, output_size, return_indices)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_adaptive_max_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# type: (Tensor, BroadcastingList1[int], bool) -> Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0madaptive_max_pool1d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m adaptive_max_pool1d = boolean_dispatch(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36madaptive_max_pool1d_with_indices\u001b[0;34m(input, output_size, return_indices)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mreturn_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mpooling\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefault\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \"\"\"\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_max_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training pipeline comes here (almost the same as for the simple_model)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train, batch_size)):\n",
    "        # Preprocessing the batch data and target\n",
    "        \n",
    "        to_model = [\n",
    "                    torch.tensor(batch['Title'], dtype=torch.long),\n",
    "                    torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
    "                    torch.tensor(batch['Categorical'])\n",
    "                    ]\n",
    "        \n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(to_model)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To hand in this homework, please upload `network.py` file with code and `submission.csv` to the google form.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Day_3_CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
